{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10245860,"sourceType":"datasetVersion","datasetId":6336682}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nfrom itertools import permutations\nimport math\nimport time\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\n\n# Load pre-trained language model for perplexity calculation\nmodel_name = \"gpt2\"\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\nmodel.eval()\n\n# Load the dataset (adjust path for Kaggle environment)\ndata_path = '/kaggle/input/my-data/sample_submission.csv'\ndata = pd.read_csv(data_path)\n\n# Define Perplexity Calculation Function\ndef calculate_perplexity(sequence):\n    \"\"\"\n    Calculate perplexity using GPT-2 model.\n    \"\"\"\n    inputs = tokenizer(sequence, return_tensors=\"pt\", truncation=True, max_length=512)\n    outputs = model(**inputs, labels=inputs[\"input_ids\"])\n    loss = outputs.loss.item()\n    perplexity = math.exp(loss)\n    return perplexity\n\n# Helper function to modify a sequence\ndef modify_sequence(sequence, reference, velocity):\n    \"\"\"\n    Modify the sequence slightly based on a reference sequence and a velocity factor.\n    \"\"\"\n    sequence = sequence.copy()\n    for _ in range(int(velocity)):\n        i, j = random.sample(range(len(sequence)), 2)\n        if sequence[i] != reference[j]:\n            sequence[i], sequence[j] = sequence[j], sequence[i]\n    return sequence\n\n# Genetic Algorithm Implementation\ndef genetic_algorithm(data, population_size=20, generations=50, mutation_rate=0.1):\n    \"\"\"\n    Genetic Algorithm to find optimal word permutations for minimal perplexity.\n    \"\"\"\n    results = []\n    for _, row in data.iterrows():\n        text_id = row['id']\n        base_sequence = row['text'].split()\n\n        # Initialize population with random permutations\n        population = [random.sample(base_sequence, len(base_sequence)) for _ in range(population_size)]\n\n        best_sequence = None\n        best_perplexity = float('inf')\n\n        for generation in range(generations):\n            # Evaluate population\n            perplexities = [calculate_perplexity(' '.join(seq)) for seq in population]\n\n            # Select top individuals (elitism)\n            sorted_indices = np.argsort(perplexities)\n            population = [population[i] for i in sorted_indices[:population_size // 2]]\n\n            # Update best sequence\n            if perplexities[sorted_indices[0]] < best_perplexity:\n                best_perplexity = perplexities[sorted_indices[0]]\n                best_sequence = population[0]\n\n            # Crossover (mate top individuals)\n            offspring = []\n            for i in range(len(population) - 1):\n                parent1, parent2 = population[i], population[i + 1]\n                split = random.randint(1, len(base_sequence) - 1)\n                child = parent1[:split] + [word for word in parent2 if word not in parent1[:split]]\n                offspring.append(child)\n\n            population.extend(offspring)\n\n            # Mutation\n            for individual in population:\n                if random.random() < mutation_rate:\n                    i, j = random.sample(range(len(base_sequence)), 2)\n                    individual[i], individual[j] = individual[j], individual[i]\n\n        results.append({'id': text_id, 'text': ' '.join(best_sequence), 'perplexity': best_perplexity})\n    \n    return pd.DataFrame(results)\n\n# Hybrid PSO-GA-SA Implementation\ndef hybrid_pso_ga_sa(data, swarm_size=20, generations=50, mutation_rate=0.1, initial_temperature=100, cooling_rate=0.95):\n    \"\"\"\n    Hybrid method combining PSO, GA, and SA to minimize perplexity.\n    \"\"\"\n    results = []\n    for _, row in data.iterrows():\n        text_id = row['id']\n        base_sequence = row['text'].split()\n\n        # Initialize swarm\n        swarm = [{'sequence': random.sample(base_sequence, len(base_sequence)), 'velocity': 1} for _ in range(swarm_size)]\n\n        best_global_sequence = None\n        best_global_perplexity = float('inf')\n\n        temperature = initial_temperature\n\n        for generation in range(generations):\n            for particle in swarm:\n                sequence = particle['sequence']\n                perplexity = calculate_perplexity(' '.join(sequence))\n\n                # Update personal best\n                if 'best_perplexity' not in particle or perplexity < particle['best_perplexity']:\n                    particle['best_perplexity'] = perplexity\n                    particle['best_sequence'] = sequence\n\n                # Update global best\n                if perplexity < best_global_perplexity:\n                    best_global_perplexity = perplexity\n                    best_global_sequence = sequence\n\n                # Update velocity and position (PSO logic)\n                inertia = particle['velocity']\n                cognitive = random.random() * 2  # Random cognitive factor\n                social = random.random() * 2    # Random social factor\n\n                particle['velocity'] = inertia + cognitive + social\n                particle['sequence'] = modify_sequence(sequence, best_global_sequence, particle['velocity'])\n\n            # Simulated Annealing\n            for particle in swarm:\n                sequence = particle['sequence']\n                perplexity = calculate_perplexity(' '.join(sequence))\n\n                delta = perplexity - best_global_perplexity\n                if delta < 0 or random.random() < math.exp(-delta / temperature):\n                    best_global_sequence = sequence\n                    best_global_perplexity = perplexity\n\n            # Cool down temperature\n            temperature *= cooling_rate\n\n        results.append({'id': text_id, 'text': ' '.join(best_global_sequence), 'perplexity': best_global_perplexity})\n\n    return pd.DataFrame(results)\n\n# Run Hybrid Method\nstart_time = time.time()\nhybrid_results = hybrid_pso_ga_sa(data)\nend_time = time.time()\n\nhybrid_results['time'] = end_time - start_time\n\n# Save results\nhybrid_results.to_csv('hybrid_method_submission.csv', index=False)\nprint(\"Hybrid PSO-GA-SA Completed. Results saved to hybrid_method_submission.csv.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-19T14:21:14.725469Z","iopub.execute_input":"2024-12-19T14:21:14.725790Z","iopub.status.idle":"2024-12-19T14:45:10.494398Z","shell.execute_reply.started":"2024-12-19T14:21:14.725769Z","shell.execute_reply":"2024-12-19T14:45:10.493480Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44405fa7ca58475d9d3c8e7d36e762d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce0dc9456db1474ba7357b4d5f1d8b62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8335215c1b5348548bcecf44f565796c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a9312647f6741cbb2d4e96936a76b04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d81685cd04254346ab4fab1047daeda8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ff1022fb9e94edea251b15f568ae54c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"556827fb2d194355ba558823101b685c"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Hybrid PSO-GA-SA Completed. Results saved to hybrid_method_submission.csv.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"hybrid_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T14:48:55.937640Z","iopub.execute_input":"2024-12-19T14:48:55.937970Z","iopub.status.idle":"2024-12-19T14:48:55.951262Z","shell.execute_reply.started":"2024-12-19T14:48:55.937947Z","shell.execute_reply":"2024-12-19T14:48:55.950577Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   id                                               text  perplexity  \\\n0   0  family scrooge chimney advent reindeer firepla...  291.528983   \n1   1  laugh fireplace ornament scrooge drive family ...  655.659109   \n2   2  nice cheer naughty beard holly yuletide chimne...  635.266642   \n3   3  decorations holiday naughty visit sleigh nice ...  897.993038   \n4   4  greeting have milk wonder joy star peppermint ...  839.852115   \n5   5  hope the give advent hohoho dream and mistleto...  735.393823   \n\n          time  \n0  1425.739339  \n1  1425.739339  \n2  1425.739339  \n3  1425.739339  \n4  1425.739339  \n5  1425.739339  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>perplexity</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>family scrooge chimney advent reindeer firepla...</td>\n      <td>291.528983</td>\n      <td>1425.739339</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>laugh fireplace ornament scrooge drive family ...</td>\n      <td>655.659109</td>\n      <td>1425.739339</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>nice cheer naughty beard holly yuletide chimne...</td>\n      <td>635.266642</td>\n      <td>1425.739339</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>decorations holiday naughty visit sleigh nice ...</td>\n      <td>897.993038</td>\n      <td>1425.739339</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>greeting have milk wonder joy star peppermint ...</td>\n      <td>839.852115</td>\n      <td>1425.739339</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>hope the give advent hohoho dream and mistleto...</td>\n      <td>735.393823</td>\n      <td>1425.739339</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nfrom itertools import permutations\nimport math\nimport time\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom gensim.models import KeyedVectors\n\n# Load pre-trained language model for perplexity calculation\nmodel_name = \"gpt2\"\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\nmodel.eval()\n\n# Load word embeddings (e.g., GloVe, Word2Vec)\n#embedding_path = '/kaggle/input/word-embeddings/word2vec.bin'  # Update with the correct path\n#embeddings = KeyedVectors.load_word2vec_format(embedding_path, binary=True)\nembeddings = None\n# Load the dataset (adjust path for Kaggle environment)\ndata_path = '/kaggle/input/my-data/sample_submission.csv'\ndata = pd.read_csv(data_path)\n\n# Define Perplexity Calculation Function\ndef calculate_perplexity(sequence):\n    \"\"\"\n    Calculate perplexity using GPT-2 model.\n    \"\"\"\n    inputs = tokenizer(sequence, return_tensors=\"pt\", truncation=True, max_length=512)\n    outputs = model(**inputs, labels=inputs[\"input_ids\"])\n    loss = outputs.loss.item()\n    perplexity = math.exp(loss)\n    return perplexity\n\n# Helper function to calculate semantic coherence\ndef calculate_coherence(sequence):\n    \"\"\"\n    Calculate semantic coherence based on word embeddings.\n    \"\"\"\n    vectors = [embeddings[word] for word in sequence if word in embeddings]\n    if len(vectors) < 2:\n        return 0\n    similarities = [cosine_similarity([vectors[i]], [vectors[i + 1]])[0][0] for i in range(len(vectors) - 1)]\n    return np.mean(similarities)\n\n# Helper function to modify a sequence\ndef modify_sequence(sequence, reference, velocity):\n    \"\"\"\n    Modify the sequence slightly based on a reference sequence and a velocity factor.\n    \"\"\"\n    sequence = sequence.copy()\n    for _ in range(int(velocity)):\n        i, j = random.sample(range(len(sequence)), 2)\n        sequence[i], sequence[j] = sequence[j], sequence[i]\n    return sequence\n\n# Genetic Algorithm Implementation\ndef genetic_algorithm(data, population_size=50, generations=100, mutation_rate=0.2):\n    \"\"\"\n    Genetic Algorithm to find optimal word permutations for minimal perplexity.\n    \"\"\"\n    results = []\n    for _, row in data.iterrows():\n        text_id = row['id']\n        base_sequence = row['text'].split()\n\n        # Initialize population with random permutations\n        population = [random.sample(base_sequence, len(base_sequence)) for _ in range(population_size)]\n\n        best_sequence = None\n        best_perplexity = float('inf')\n\n        for generation in range(generations):\n            # Evaluate population\n            perplexities = [calculate_perplexity(' '.join(seq)) for seq in population]\n            coherences = [calculate_coherence(seq) for seq in population]\n\n            # Combine perplexity and coherence scores\n            scores = [perplexities[i] - 0.1 * coherences[i] for i in range(len(population))]\n\n            # Select top individuals (elitism)\n            sorted_indices = np.argsort(scores)\n            population = [population[i] for i in sorted_indices[:population_size // 2]]\n\n            # Update best sequence\n            if scores[sorted_indices[0]] < best_perplexity:\n                best_perplexity = scores[sorted_indices[0]]\n                best_sequence = population[0]\n\n            # Crossover (mate top individuals)\n            offspring = []\n            for i in range(len(population) - 1):\n                parent1, parent2 = population[i], population[i + 1]\n                split = random.randint(1, len(base_sequence) - 1)\n                child = parent1[:split] + [word for word in parent2 if word not in parent1[:split]]\n                offspring.append(child)\n\n            population.extend(offspring)\n\n            # Mutation\n            for individual in population:\n                if random.random() < mutation_rate:\n                    i, j = random.sample(range(len(base_sequence)), 2)\n                    individual[i], individual[j] = individual[j], individual[i]\n\n            # Introduce random new individuals periodically\n            if generation % 10 == 0:\n                new_individuals = [random.sample(base_sequence, len(base_sequence)) for _ in range(population_size // 10)]\n                population.extend(new_individuals)\n\n        results.append({'id': text_id, 'text': ' '.join(best_sequence), 'perplexity': best_perplexity})\n    \n    return pd.DataFrame(results)\n\n# Hybrid PSO-GA-SA Implementation\ndef hybrid_pso_ga_sa(data, swarm_size=50, generations=100, mutation_rate=0.2, initial_temperature=100, cooling_rate=0.95):\n    \"\"\"\n    Hybrid method combining PSO, GA, and SA to minimize perplexity.\n    \"\"\"\n    results = []\n    for _, row in data.iterrows():\n        text_id = row['id']\n        base_sequence = row['text'].split()\n\n        # Initialize swarm\n        swarm = [{'sequence': random.sample(base_sequence, len(base_sequence)), 'velocity': 1} for _ in range(swarm_size)]\n\n        best_global_sequence = None\n        best_global_perplexity = float('inf')\n\n        temperature = initial_temperature\n\n        for generation in range(generations):\n            for particle in swarm:\n                sequence = particle['sequence']\n                perplexity = calculate_perplexity(' '.join(sequence))\n                coherence = calculate_coherence(sequence)\n\n                # Update personal best\n                if 'best_perplexity' not in particle or perplexity - 0.1 * coherence < particle['best_perplexity']:\n                    particle['best_perplexity'] = perplexity - 0.1 * coherence\n                    particle['best_sequence'] = sequence\n\n                # Update global best\n                if perplexity - 0.1 * coherence < best_global_perplexity:\n                    best_global_perplexity = perplexity - 0.1 * coherence\n                    best_global_sequence = sequence\n\n                # Update velocity and position (PSO logic)\n                inertia = particle['velocity']\n                cognitive = random.random() * 2  # Random cognitive factor\n                social = random.random() * 2    # Random social factor\n\n                particle['velocity'] = inertia + cognitive + social\n                particle['sequence'] = modify_sequence(sequence, best_global_sequence, particle['velocity'])\n\n            # Simulated Annealing\n            for particle in swarm:\n                sequence = particle['sequence']\n                perplexity = calculate_perplexity(' '.join(sequence))\n                coherence = calculate_coherence(sequence)\n\n                delta = (perplexity - 0.1 * coherence) - best_global_perplexity\n                if delta < 0 or random.random() < math.exp(-delta / temperature):\n                    best_global_sequence = sequence\n                    best_global_perplexity = perplexity - 0.1 * coherence\n\n            # Cool down temperature\n            temperature *= cooling_rate\n\n            # Add random diversity\n            if generation % 10 == 0:\n                random_particles = [{'sequence': random.sample(base_sequence, len(base_sequence)), 'velocity': 1} for _ in range(swarm_size // 10)]\n                swarm.extend(random_particles)\n\n        results.append({'id': text_id, 'text': ' '.join(best_global_sequence), 'perplexity': best_global_perplexity})\n\n    return pd.DataFrame(results)\n\n# Run Hybrid Method\nstart_time = time.time()\nhybrid_results = hybrid_pso_ga_sa(data)\nend_time = time.time()\n\nhybrid_results['time'] = end_time - start_time\n\n# Save results\nhybrid_results.to_csv('hybrid_method_submission.csv', index=False)\nprint(\"Hybrid PSO-GA-SA Completed. Results saved to hybrid_method_submission.csv.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T15:12:57.511863Z","iopub.execute_input":"2024-12-19T15:12:57.512305Z","iopub.status.idle":"2024-12-19T15:13:10.604595Z","shell.execute_reply.started":"2024-12-19T15:12:57.512274Z","shell.execute_reply":"2024-12-19T15:13:10.603242Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-aac33dff06bf>\u001b[0m in \u001b[0;36m<cell line: 183>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;31m# Run Hybrid Method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m \u001b[0mhybrid_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhybrid_pso_ga_sa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-aac33dff06bf>\u001b[0m in \u001b[0;36mhybrid_pso_ga_sa\u001b[0;34m(data, swarm_size, generations, mutation_rate, initial_temperature, cooling_rate)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparticle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mperplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 \u001b[0mcoherence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_coherence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;31m# Update personal best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-aac33dff06bf>\u001b[0m in \u001b[0;36mcalculate_coherence\u001b[0;34m(sequence)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mCalculate\u001b[0m \u001b[0msemantic\u001b[0m \u001b[0mcoherence\u001b[0m \u001b[0mbased\u001b[0m \u001b[0mon\u001b[0m \u001b[0mword\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-aac33dff06bf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mCalculate\u001b[0m \u001b[0msemantic\u001b[0m \u001b[0mcoherence\u001b[0m \u001b[0mbased\u001b[0m \u001b[0mon\u001b[0m \u001b[0mword\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"],"ename":"TypeError","evalue":"argument of type 'NoneType' is not iterable","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}